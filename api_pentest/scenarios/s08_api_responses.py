import logging
import re

from api_pentest.core.models import Severity, TestStatus
from api_pentest.scenarios.base_scenario import BaseScenario

logger = logging.getLogger(__name__)


class S08APIResponses(BaseScenario):
    """S08 - API Response Data Exposure detection."""

    SCENARIO_ID = "S08"
    SCENARIO_NAME = "API Response Data Exposure"
    OWASP_ID = "API3:2023"
    OWASP_NAME = "Broken Object Property Level Authorization"

    SENSITIVE_FIELD_PATTERNS = re.compile(
        r'"(password|passwd|pwd|secret|api_key|apikey|api_secret|'
        r'access_token|refresh_token|private_key|credit_card|'
        r'card_number|cvv|cvc|ssn|social_security|'
        r'bank_account|routing_number|'
        r'auth_token|session_id|session_token|'
        r'secret_key|encryption_key|'
        r'otp|mfa_secret|totp_secret)"\s*:',
        re.IGNORECASE,
    )

    SENSITIVE_DATA_PATTERNS = re.compile(
        r'(\b\d{3}-\d{2}-\d{4}\b|'  # SSN
        r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b|'  # Credit card
        r'\b[A-Za-z0-9+/]{40,}={0,2}\b)',  # Long base64 (potential keys)
        re.IGNORECASE,
    )

    VERBOSE_ERROR_PATTERNS = re.compile(
        r'(Traceback \(most recent|at [\w.]+\([\w.]+:\d+\)|'
        r'Exception in thread|java\.lang\.|'
        r'System\.NullReferenceException|'
        r'Fatal error:|PHP Fatal|PHP Warning|'
        r'SQLSTATE\[|mysql_|pg_query|sqlite3_|'
        r'/usr/|/var/|/home/|/opt/|C:\\\\|'
        r'stack trace|internal server error.*detail|'
        r'debug.*true|verbose.*error)',
        re.IGNORECASE,
    )

    INFO_LEAK_HEADERS = [
        "Server",
        "X-Powered-By",
        "X-AspNet-Version",
        "X-Debug-Token",
        "X-Debug-Token-Link",
        "X-Runtime",
        "X-Request-Id",
    ]

    # Fields that are expected in auth-endpoint responses (login, token, etc.)
    EXPECTED_AUTH_FIELDS = {
        "auth_token", "access_token", "refresh_token",
        "token", "session_token", "session_id",
    }

    def get_test_cases(self) -> list[str]:
        cases = [
            "sensitive_field_exposure",
            "verbose_error_detection",
            "response_header_info_leak",
        ]
        if self.oauth and self.oauth_b:
            cases.append("cross_role_field_comparison")
        return cases

    def execute_test(self, test_name: str):
        if test_name == "sensitive_field_exposure":
            self._test_sensitive_field_exposure()
        elif test_name == "verbose_error_detection":
            self._test_verbose_error_detection()
        elif test_name == "response_header_info_leak":
            self._test_response_header_info_leak()
        elif test_name == "cross_role_field_comparison":
            self._test_cross_role_field_comparison()

    def _test_sensitive_field_exposure(self):
        """Check if API responses contain sensitive data fields."""
        token = self.get_token_a()
        sensitive_found = False

        for ep in self.endpoints:
            evidence = self.make_request(ep, token=token)

            if not self.is_success_status(evidence.response_status):
                continue

            body = evidence.response_body

            # Check for sensitive field names
            field_matches = self.SENSITIVE_FIELD_PATTERNS.findall(body)
            if field_matches:
                # Filter out expected auth fields for auth-endpoints
                if self.is_auth_endpoint(ep):
                    field_matches = [
                        f for f in field_matches
                        if f.lower() not in self.EXPECTED_AUTH_FIELDS
                    ]
                    if not field_matches:
                        logger.debug(
                            "Skipping sensitive field finding for auth-endpoint %s %s: "
                            "fields are expected auth response (%s)",
                            ep.method, ep.url, ep.classification_reason,
                        )

                if field_matches:
                    unique_fields = list(set(field_matches))
                    sensitive_found = True
                    self.add_result(
                        "sensitive_field_exposure",
                        TestStatus.FAIL,
                        f"Sensitive fields in response: {', '.join(unique_fields)} at {ep.method} {ep.url}",
                        endpoint_name=ep.full_name,
                        evidence=evidence,
                    )
                    self.log_finding(
                        severity=Severity.HIGH,
                        title=f"Sensitive data fields exposed in {ep.method} {ep.url}",
                        description=(
                            f"Response contains sensitive field(s): {', '.join(unique_fields)}. "
                            "These fields should be filtered from API responses."
                        ),
                        endpoint=f"{ep.method} {ep.url}",
                        evidence=evidence,
                        remediation=(
                            "Use response DTOs/serializers to explicitly whitelist returned fields. "
                            "Never return sensitive fields like passwords, tokens, or keys."
                        ),
                    )

            # Check for sensitive data patterns
            data_matches = self.SENSITIVE_DATA_PATTERNS.findall(body)
            if data_matches:
                sensitive_found = True
                self.log_finding(
                    severity=Severity.MEDIUM,
                    title=f"Potential sensitive data in {ep.method} {ep.url}",
                    description=(
                        f"Response may contain sensitive data patterns "
                        f"(SSN, credit card, or encoded keys)."
                    ),
                    endpoint=f"{ep.method} {ep.url}",
                    evidence=evidence,
                    remediation="Review data returned by this endpoint. Mask or remove sensitive values.",
                )

        if not sensitive_found:
            self.add_result(
                "sensitive_field_exposure",
                TestStatus.PASS,
                "No sensitive fields detected in responses",
            )

    def _test_verbose_error_detection(self):
        """Check if error responses expose internal details."""
        token = self.get_token_a()
        verbose_found = False

        # Trigger errors with bad input
        error_triggers = [
            {"override_url_suffix": "/nonexistent-path-12345"},
            {"override_body": "not-json-{{{"},
            {"override_body": {"id": "'; DROP TABLE--"}},
            {"override_method": "INVALID"},
        ]

        for ep in self.endpoints[:10]:
            # Normal error (bad path)
            from urllib.parse import urlparse
            parsed = urlparse(ep.url)
            bad_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}/nonexistent-12345"
            evidence = self.make_request(ep, token=token, override_url=bad_url)

            if evidence.response_body:
                matches = self.VERBOSE_ERROR_PATTERNS.findall(evidence.response_body)
                if matches:
                    verbose_found = True
                    self.add_result(
                        "verbose_error_detection",
                        TestStatus.FAIL,
                        f"Verbose error at {bad_url}: {matches[0][:80]}",
                        endpoint_name=ep.full_name,
                        evidence=evidence,
                    )
                    self.log_finding(
                        severity=Severity.MEDIUM,
                        title="Verbose error message exposes internal details",
                        description=(
                            f"Error response from {bad_url} contains internal details: "
                            f"'{matches[0][:100]}'. This may reveal stack traces, file paths, "
                            "or database information."
                        ),
                        endpoint=f"GET {bad_url}",
                        evidence=evidence,
                        remediation=(
                            "Return generic error messages in production. "
                            "Log detailed errors server-side only."
                        ),
                    )

            # Also try sending bad body to POST/PUT endpoints
            if ep.method.upper() in ("POST", "PUT", "PATCH"):
                evidence = self.make_request(
                    ep, token=token, override_body="<<<INVALID JSON>>>"
                )
                if evidence.response_body:
                    matches = self.VERBOSE_ERROR_PATTERNS.findall(evidence.response_body)
                    if matches:
                        verbose_found = True
                        self.log_finding(
                            severity=Severity.MEDIUM,
                            title=f"Verbose error on malformed body at {ep.method} {ep.url}",
                            description=f"Sending invalid body triggered detailed error: '{matches[0][:100]}'",
                            endpoint=f"{ep.method} {ep.url}",
                            evidence=evidence,
                            remediation="Validate request body format and return generic 400 errors.",
                        )

        if not verbose_found:
            self.add_result(
                "verbose_error_detection",
                TestStatus.PASS,
                "No verbose error messages detected",
            )

    def _test_response_header_info_leak(self):
        """Check for information leakage in response headers."""
        token = self.get_token_a()
        ep = self.endpoints[0] if self.endpoints else None
        if not ep:
            self.add_result("response_header_info_leak", TestStatus.SKIP, "No endpoints")
            return

        evidence = self.make_request(ep, token=token)
        leaks = []

        for header_name in self.INFO_LEAK_HEADERS:
            # Case-insensitive header lookup
            for resp_header, value in evidence.response_headers.items():
                if resp_header.lower() == header_name.lower():
                    leaks.append(f"{resp_header}: {value}")

        if leaks:
            self.add_result(
                "response_header_info_leak",
                TestStatus.FAIL,
                f"Info leak headers found: {'; '.join(leaks)}",
                evidence=evidence,
            )
            self.log_finding(
                severity=Severity.LOW,
                title="Information leakage via response headers",
                description=(
                    f"The following headers may reveal server technology details: "
                    f"{'; '.join(leaks)}"
                ),
                endpoint=f"{ep.method} {ep.url}",
                evidence=evidence,
                remediation=(
                    "Remove or customize Server, X-Powered-By, and debug headers "
                    "in production environments."
                ),
            )
        else:
            self.add_result(
                "response_header_info_leak",
                TestStatus.PASS,
                "No information leakage headers detected",
                evidence=evidence,
            )

    def _test_cross_role_field_comparison(self):
        """Compare response fields between User A and User B to detect over-exposure."""
        token_a = self.get_token_a()
        token_b = self.get_token_b()

        if not token_a or not token_b:
            self.add_result(
                "cross_role_field_comparison",
                TestStatus.SKIP,
                "Need both User A and B tokens",
            )
            return

        over_exposure = False
        tested = 0

        for ep in self.endpoints[:10]:
            if ep.method.upper() != "GET":
                continue

            resp_a = self.make_request(ep, token=token_a)
            resp_b = self.make_request(ep, token=token_b)

            if not (
                self.is_success_status(resp_a.response_status)
                and self.is_success_status(resp_b.response_status)
            ):
                continue

            tested += 1

            # Compare response field sets
            try:
                import json
                data_a = json.loads(resp_a.response_body)
                data_b = json.loads(resp_b.response_body)

                fields_a = self._extract_field_names(data_a)
                fields_b = self._extract_field_names(data_b)

                extra_in_a = fields_a - fields_b
                extra_in_b = fields_b - fields_a

                if extra_in_a or extra_in_b:
                    over_exposure = True
                    details = []
                    if extra_in_a:
                        details.append(f"Extra in User A: {', '.join(sorted(extra_in_a)[:10])}")
                    if extra_in_b:
                        details.append(f"Extra in User B: {', '.join(sorted(extra_in_b)[:10])}")

                    self.add_result(
                        "cross_role_field_comparison",
                        TestStatus.FAIL,
                        f"Field difference at {ep.method} {ep.url}: {'; '.join(details)}",
                        endpoint_name=ep.full_name,
                    )
                    self.log_finding(
                        severity=Severity.MEDIUM,
                        title=f"Different field sets returned for different users at {ep.url}",
                        description=(
                            f"GET {ep.url} returns different fields for User A vs User B. "
                            f"{'; '.join(details)}. This may indicate role-based field filtering, "
                            "or it may reveal data that should be restricted."
                        ),
                        endpoint=f"{ep.method} {ep.url}",
                        remediation="Ensure response field filtering is intentional and based on user permissions.",
                    )
            except (ValueError, TypeError):
                continue

        if not over_exposure:
            self.add_result(
                "cross_role_field_comparison",
                TestStatus.PASS,
                f"Consistent field sets across roles ({tested} endpoints compared)",
            )

    def _extract_field_names(self, data, prefix: str = "") -> set[str]:
        """Recursively extract all field names from a JSON structure."""
        fields = set()
        if isinstance(data, dict):
            for key, value in data.items():
                full_key = f"{prefix}.{key}" if prefix else key
                fields.add(full_key)
                fields.update(self._extract_field_names(value, full_key))
        elif isinstance(data, list) and data:
            fields.update(self._extract_field_names(data[0], prefix))
        return fields
