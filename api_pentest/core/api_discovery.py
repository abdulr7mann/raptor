"""
API Discovery module for detecting authentication schemes and architecture types.

This module provides:
- AuthDetector: Detects auth schemes from OpenAPI specs and active probing
- ArchitectureDetector: Identifies REST/GraphQL/SOAP architecture types
- RequestBudget: Shared request counter across detection subsystems
- Supporting enums and dataclasses
"""

import json
import logging
import re
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

from api_pentest.core.models import Evidence

logger = logging.getLogger(__name__)


# =============================================================================
# Enums
# =============================================================================


class AuthSchemeType(Enum):
    """Authentication scheme types detected from specs or probing."""

    BEARER = "bearer"
    API_KEY = "apiKey"
    BASIC = "basic"
    OAUTH2 = "oauth2"
    SESSION_COOKIE = "session_cookie"
    OPENID_CONNECT = "openIdConnect"
    UNKNOWN = "unknown"


class ArchitectureType(Enum):
    """API architecture types."""

    REST = "REST"
    GRAPHQL = "GraphQL"
    SOAP = "SOAP"
    GRPC_WEB = "gRPC-web"
    HYBRID = "hybrid"
    UNKNOWN = "unknown"


# =============================================================================
# Dataclasses
# =============================================================================


@dataclass
class DetectedAuthScheme:
    """Represents a detected authentication scheme."""

    scheme_type: AuthSchemeType
    name: str  # e.g. "bearerAuth", "api_key"
    source: str  # "spec" or "probe"
    details: dict = field(default_factory=dict)
    # For apiKey: {"in": "header", "name": "X-API-Key"}
    # For bearer: {"format": "JWT"}
    # For oauth2: {"flows": {"clientCredentials": {"tokenUrl": "..."}}}
    endpoints: list[str] = field(default_factory=list)  # which endpoints use this scheme


# =============================================================================
# RequestBudget
# =============================================================================


class RequestBudget:
    """Tracks and limits the number of discovery requests.

    All detector subsystems share one RequestBudget instance to ensure
    the total discovery request count stays within the configured cap.
    """

    def __init__(self, max_requests: int = 30):
        self.max_requests = max_requests
        self.used = 0

    def can_request(self) -> bool:
        """Check if another request can be made within budget."""
        return self.used < self.max_requests

    def record(self):
        """Record that a request was made."""
        self.used += 1

    @property
    def remaining(self) -> int:
        """Number of requests remaining in budget."""
        return max(0, self.max_requests - self.used)


# =============================================================================
# AuthDetector
# =============================================================================


class AuthDetector:
    """Detects authentication schemes using spec extraction + active probing.

    Two-tier strategy (per CONTEXT.md):
    1. Tier 1: Extract from OpenAPI spec (cheapest, most reliable)
    2. Tier 2: Active probing as fallback (when spec is missing or lacks security info)
    """

    # Session cookie names to detect
    SESSION_COOKIE_NAMES = frozenset({
        "session",
        "sid",
        "sessionid",
        "jsessionid",
        "connect.sid",
        "phpsessid",
        "asp.net_sessionid",
        "aspsessionid",
    })

    def __init__(
        self,
        openapi_spec: dict | None,
        http_client: Any,
        endpoints: list,
        base_url: str,
        budget: RequestBudget,
    ):
        """Initialize AuthDetector.

        Args:
            openapi_spec: Parsed OpenAPI/Swagger spec dict, or None
            http_client: PentestHttpClient instance for active probing
            endpoints: List of Endpoint objects to probe
            base_url: Base URL of the API
            budget: Shared RequestBudget instance
        """
        self.spec = openapi_spec
        self.http = http_client
        self.endpoints = endpoints
        self.base_url = base_url.rstrip("/") if base_url else ""
        self.budget = budget

    def detect(self) -> list[DetectedAuthScheme]:
        """Detect authentication schemes.

        Returns a list of DetectedAuthScheme objects found via spec extraction
        or active probing.
        """
        schemes = []

        # Tier 1: Spec extraction (zero requests needed)
        if self.spec:
            schemes.extend(self._extract_from_spec())
            if schemes:
                logger.info(
                    "Detected %d auth scheme(s) from spec: %s",
                    len(schemes),
                    [s.name for s in schemes],
                )

        # Tier 2: Active probing (only if Tier 1 found nothing)
        if not schemes and self.http and self.endpoints:
            logger.info("No auth schemes in spec, falling back to active probing")
            schemes.extend(self._probe_unauthenticated())
            if schemes:
                logger.info(
                    "Detected %d auth scheme(s) via probing: %s",
                    len(schemes),
                    [s.name for s in schemes],
                )

        if not schemes:
            logger.warning("No authentication schemes detected")

        return schemes

    def _extract_from_spec(self) -> list[DetectedAuthScheme]:
        """Extract auth schemes from OpenAPI spec.

        Handles both Swagger 2.0 (securityDefinitions) and
        OpenAPI 3.x (components.securitySchemes).
        """
        if not self.spec:
            return []

        # Get raw security schemes from appropriate location
        raw_schemes: dict = {}

        # Swagger 2.0 uses securityDefinitions at root
        if "securityDefinitions" in self.spec:
            raw_schemes = self.spec.get("securityDefinitions", {})
            logger.debug("Found securityDefinitions (Swagger 2.0)")

        # OpenAPI 3.x uses components.securitySchemes
        elif "components" in self.spec:
            raw_schemes = self.spec.get("components", {}).get("securitySchemes", {})
            logger.debug("Found components.securitySchemes (OpenAPI 3.x)")

        if not raw_schemes:
            logger.debug("No security schemes found in spec")
            return []

        detected = []
        for name, scheme_def in raw_schemes.items():
            if not isinstance(scheme_def, dict):
                continue

            scheme_type = self._map_spec_type(scheme_def)
            detected.append(
                DetectedAuthScheme(
                    scheme_type=scheme_type,
                    name=name,
                    source="spec",
                    details=self._extract_scheme_details(scheme_def),
                    endpoints=self._find_endpoints_using_scheme(name),
                )
            )

        return detected

    def _map_spec_type(self, scheme_def: dict) -> AuthSchemeType:
        """Map OpenAPI/Swagger type field to AuthSchemeType enum.

        Handles BOTH formats:
        - OpenAPI 3.x: type:"http" + scheme:"bearer" -> BEARER
        - OpenAPI 3.x: type:"http" + scheme:"basic" -> BASIC
        - OpenAPI 3.x: type:"apiKey" -> API_KEY
        - OpenAPI 3.x: type:"oauth2" -> OAUTH2
        - OpenAPI 3.x: type:"openIdConnect" -> OPENID_CONNECT
        - Swagger 2.0: type:"basic" (direct, no scheme field) -> BASIC
        """
        spec_type = scheme_def.get("type", "").lower()

        # OpenAPI 3.x http scheme
        if spec_type == "http":
            http_scheme = scheme_def.get("scheme", "").lower()
            if http_scheme == "bearer":
                return AuthSchemeType.BEARER
            elif http_scheme == "basic":
                return AuthSchemeType.BASIC
            return AuthSchemeType.UNKNOWN

        # OpenAPI 3.x apiKey
        elif spec_type == "apikey":
            return AuthSchemeType.API_KEY

        # OpenAPI 3.x oauth2
        elif spec_type == "oauth2":
            return AuthSchemeType.OAUTH2

        # OpenAPI 3.x openIdConnect
        elif spec_type == "openidconnect":
            return AuthSchemeType.OPENID_CONNECT

        # Swagger 2.0 uses type: "basic" directly (no scheme field needed)
        elif spec_type == "basic":
            return AuthSchemeType.BASIC

        return AuthSchemeType.UNKNOWN

    def _extract_scheme_details(self, scheme_def: dict) -> dict:
        """Extract relevant details from a security scheme definition."""
        details = {}
        spec_type = scheme_def.get("type", "").lower()

        # Copy raw type and scheme
        if "type" in scheme_def:
            details["type"] = scheme_def["type"]
        if "scheme" in scheme_def:
            details["scheme"] = scheme_def["scheme"]

        # Bearer-specific: bearerFormat
        if scheme_def.get("bearerFormat"):
            details["format"] = scheme_def["bearerFormat"]

        # apiKey-specific: in, name
        if spec_type == "apikey":
            if "in" in scheme_def:
                details["in"] = scheme_def["in"]
            if "name" in scheme_def:
                details["name"] = scheme_def["name"]

        # oauth2-specific: flows
        if spec_type == "oauth2" and "flows" in scheme_def:
            details["flows"] = scheme_def["flows"]

        # Swagger 2.0 oauth2: flow, authorizationUrl, tokenUrl, scopes
        if spec_type == "oauth2":
            for key in ("flow", "authorizationUrl", "tokenUrl", "scopes"):
                if key in scheme_def:
                    details[key] = scheme_def[key]

        # openIdConnect-specific: openIdConnectUrl
        if "openIdConnectUrl" in scheme_def:
            details["openIdConnectUrl"] = scheme_def["openIdConnectUrl"]

        return details

    def _find_endpoints_using_scheme(self, scheme_name: str) -> list[str]:
        """Find which endpoints reference a given security scheme.

        Checks both per-operation security and global security in the spec.
        Returns endpoints in "METHOD /path" format.
        """
        if not self.spec:
            return []

        using_scheme = []

        # Check global security
        global_security = self.spec.get("security", [])
        global_uses_scheme = any(
            scheme_name in sec_req
            for sec_req in global_security
            if isinstance(sec_req, dict)
        )

        paths = self.spec.get("paths", {})
        for path, path_item in paths.items():
            if not isinstance(path_item, dict):
                continue

            for method in ("get", "post", "put", "delete", "patch", "head", "options"):
                operation = path_item.get(method)
                if not operation or not isinstance(operation, dict):
                    continue

                op_security = operation.get("security")

                if op_security is not None:
                    # Explicit per-operation security
                    # Empty array [] means no auth required
                    if op_security == []:
                        continue
                    if any(
                        scheme_name in sec_req
                        for sec_req in op_security
                        if isinstance(sec_req, dict)
                    ):
                        using_scheme.append(f"{method.upper()} {path}")
                elif global_uses_scheme:
                    # Inherits global security
                    using_scheme.append(f"{method.upper()} {path}")

        return using_scheme

    def _select_probe_endpoints(self, count: int = 5) -> list:
        """Select representative endpoints for probing.

        Prefers GET endpoints, mixes paths for variety.
        """
        if not self.endpoints:
            return []

        # Prefer GET endpoints (safe methods)
        get_endpoints = [
            ep for ep in self.endpoints if ep.method.upper() == "GET"
        ]
        other_endpoints = [
            ep for ep in self.endpoints if ep.method.upper() != "GET"
        ]

        # Mix: prioritize GET, fill with others
        selected = []
        selected.extend(get_endpoints[:count])

        if len(selected) < count:
            remaining = count - len(selected)
            selected.extend(other_endpoints[:remaining])

        return selected[:count]

    def _probe_unauthenticated(self) -> list[DetectedAuthScheme]:
        """Send unauthenticated requests, parse 401/403 responses.

        Only probes with safe methods (GET, HEAD, OPTIONS).
        Never POST/PUT/DELETE for auth probing.
        """
        schemes = []
        seen_types: set[AuthSchemeType] = set()
        evidence_list: list[Evidence] = []

        probe_endpoints = self._select_probe_endpoints(count=5)

        for ep in probe_endpoints:
            # Check budget before each request
            if not self.budget.can_request():
                logger.warning(
                    "Discovery request budget exhausted, %d endpoints unprobed",
                    len(probe_endpoints) - probe_endpoints.index(ep),
                )
                break

            # Only use safe methods for probing
            method = ep.method.upper()
            if method not in ("GET", "HEAD", "OPTIONS"):
                # For non-safe methods, use HEAD instead
                method = "HEAD"

            try:
                evidence = self.http.request(
                    method=method,
                    url=ep.url,
                    headers={},
                )
                self.budget.record()
                evidence_list.append(evidence)

                if evidence.response_status in (401, 403):
                    # Parse WWW-Authenticate header
                    detected = self._parse_www_authenticate(evidence)
                    for d in detected:
                        if d.scheme_type not in seen_types:
                            seen_types.add(d.scheme_type)
                            schemes.append(d)

                    # Detect cookie-based auth from Set-Cookie
                    cookie_scheme = self._detect_session_cookie(evidence)
                    if cookie_scheme and AuthSchemeType.SESSION_COOKIE not in seen_types:
                        seen_types.add(AuthSchemeType.SESSION_COOKIE)
                        schemes.append(cookie_scheme)

            except Exception as e:
                logger.debug("Probe request failed for %s: %s", ep.url, e)
                continue

        return schemes

    def _parse_www_authenticate(self, evidence: Evidence) -> list[DetectedAuthScheme]:
        """Parse WWW-Authenticate header per RFC 7235.

        Matches known scheme names (Bearer, Basic, Digest, OAuth) via regex.
        Extracts realm if present.
        """
        schemes = []

        # Find WWW-Authenticate header (case-insensitive)
        www_auth = None
        for header_name, header_val in evidence.response_headers.items():
            if header_name.lower() == "www-authenticate":
                www_auth = header_val
                break

        if not www_auth:
            # No WWW-Authenticate header -- infer from status code
            return self._infer_from_status(evidence)

        # Parse multiple challenges (comma-separated at top level)
        # Match known scheme keywords
        scheme_pattern = re.compile(
            r"\b(Bearer|Basic|Digest|Negotiate|HOBA|OAuth)\b",
            re.IGNORECASE,
        )

        seen_scheme_names: set[str] = set()
        matches = scheme_pattern.finditer(www_auth)

        for match in matches:
            scheme_name = match.group(1).lower()

            # Avoid duplicates in same header
            if scheme_name in seen_scheme_names:
                continue
            seen_scheme_names.add(scheme_name)

            scheme_type_map = {
                "bearer": AuthSchemeType.BEARER,
                "basic": AuthSchemeType.BASIC,
                "digest": AuthSchemeType.UNKNOWN,  # Track but don't deeply support
                "negotiate": AuthSchemeType.UNKNOWN,
                "hoba": AuthSchemeType.UNKNOWN,
                "oauth": AuthSchemeType.OAUTH2,
            }
            scheme_type = scheme_type_map.get(scheme_name, AuthSchemeType.UNKNOWN)

            # Extract realm if present (search from match position)
            realm_match = re.search(r'realm="([^"]*)"', www_auth[match.start() :])
            realm = realm_match.group(1) if realm_match else ""

            schemes.append(
                DetectedAuthScheme(
                    scheme_type=scheme_type,
                    name=scheme_name,
                    source="probe",
                    details={"realm": realm, "raw_header": www_auth},
                )
            )

        return schemes

    def _detect_session_cookie(self, evidence: Evidence) -> DetectedAuthScheme | None:
        """Detect session cookie from Set-Cookie header."""
        for header_name, header_val in evidence.response_headers.items():
            if header_name.lower() == "set-cookie":
                # Check for session-like cookie names
                cookie_lower = header_val.lower()
                for session_name in self.SESSION_COOKIE_NAMES:
                    if session_name in cookie_lower:
                        return DetectedAuthScheme(
                            scheme_type=AuthSchemeType.SESSION_COOKIE,
                            name="session_cookie",
                            source="probe",
                            details={
                                "cookie_name_pattern": session_name,
                                "raw_header": header_val,
                            },
                        )
        return None

    def _infer_from_status(self, evidence: Evidence) -> list[DetectedAuthScheme]:
        """Infer auth requirement from status code when no WWW-Authenticate header.

        Returns UNKNOWN scheme with status code details.
        """
        if evidence.response_status in (401, 403):
            return [
                DetectedAuthScheme(
                    scheme_type=AuthSchemeType.UNKNOWN,
                    name="unknown",
                    source="probe",
                    details={
                        "status_code": evidence.response_status,
                        "note": "Auth required but scheme not specified in WWW-Authenticate header",
                    },
                )
            ]
        return []


# =============================================================================
# GraphQL Introspection Query
# =============================================================================

# Standard top-level introspection query (per graphql.org/learn/introspection/)
# Uses modern `locations` field for directives (not legacy onOperation/onFragment/onField)
GRAPHQL_INTROSPECTION_QUERY = """
query IntrospectionQuery {
  __schema {
    queryType { name }
    mutationType { name }
    subscriptionType { name }
    types {
      kind
      name
      description
      fields(includeDeprecated: true) {
        name
        description
        args {
          name
          description
          type {
            kind
            name
            ofType { kind name ofType { kind name } }
          }
          defaultValue
        }
        type {
          kind
          name
          ofType { kind name ofType { kind name } }
        }
        isDeprecated
        deprecationReason
      }
      inputFields {
        name
        type {
          kind
          name
          ofType { kind name }
        }
        defaultValue
      }
      interfaces { kind name }
      enumValues(includeDeprecated: true) {
        name
        description
        isDeprecated
        deprecationReason
      }
      possibleTypes { kind name }
    }
    directives {
      name
      description
      locations
      args {
        name
        type {
          kind
          name
          ofType { kind name }
        }
        defaultValue
      }
    }
  }
}
"""


# =============================================================================
# ArchitectureDetector
# =============================================================================


class ArchitectureDetector:
    """Detects API architecture type from spec and probing.

    Identifies REST, GraphQL, SOAP, or hybrid architectures.
    GraphQL detection includes introspection attempts.
    """

    GRAPHQL_PATHS = ["/graphql", "/api/graphql", "/gql", "/query"]

    # Security header names to collect
    SECURITY_HEADER_NAMES = frozenset({
        "x-content-type-options",
        "x-frame-options",
        "strict-transport-security",
        "x-xss-protection",
        "content-security-policy",
        "referrer-policy",
        "permissions-policy",
        "x-permitted-cross-domain-policies",
    })

    def __init__(
        self,
        openapi_spec: dict | None,
        http_client: Any,
        base_url: str,
        budget: RequestBudget,
    ):
        """Initialize ArchitectureDetector.

        Args:
            openapi_spec: Parsed OpenAPI/Swagger spec dict, or None
            http_client: PentestHttpClient instance for active probing
            base_url: Base URL of the API
            budget: Shared RequestBudget instance
        """
        self.spec = openapi_spec
        self.http = http_client
        self.base_url = base_url.rstrip("/") if base_url else ""
        self.budget = budget
        self._evidence_list: list[Evidence] = []

    def detect(self) -> tuple[ArchitectureType, dict]:
        """Detect API architecture type.

        Returns:
            Tuple of (ArchitectureType, details_dict) where details contains
            architecture-specific information and server info.
        """
        signals = {
            "rest": False,
            "graphql": False,
            "soap": False,
        }
        details: dict[str, Any] = {}

        # Spec signals
        if self.spec:
            # OpenAPI/Swagger spec indicates REST
            if self.spec.get("openapi") or self.spec.get("swagger"):
                signals["rest"] = True
                logger.debug("REST signal: OpenAPI/Swagger spec detected")

            # Check for GraphQL paths in spec
            paths = self.spec.get("paths", {})
            for path_key in paths:
                if any(gql_path in path_key.lower() for gql_path in self.GRAPHQL_PATHS):
                    signals["graphql"] = True
                    logger.debug("GraphQL signal: Found GraphQL path in spec: %s", path_key)

        # Active probing: check for GraphQL endpoints
        # GraphQL POST is allowed as read-only exception to no-mutation rule
        graphql_result = self._probe_graphql()
        if graphql_result:
            signals["graphql"] = True
            details["graphql"] = graphql_result

        # Collect server info from all evidence gathered during probing
        if self._evidence_list:
            details["server_info"] = self._collect_server_info(self._evidence_list)

        # Count signals and determine architecture type
        detected = [k for k, v in signals.items() if v]
        if len(detected) > 1:
            arch_type = ArchitectureType.HYBRID
            logger.info("Architecture detected: HYBRID (%s)", detected)
        elif "graphql" in detected:
            arch_type = ArchitectureType.GRAPHQL
            logger.info("Architecture detected: GraphQL")
        elif "soap" in detected:
            arch_type = ArchitectureType.SOAP
            logger.info("Architecture detected: SOAP")
        elif "rest" in detected:
            arch_type = ArchitectureType.REST
            logger.info("Architecture detected: REST")
        else:
            arch_type = ArchitectureType.UNKNOWN
            logger.warning("Architecture detection: UNKNOWN (no signals)")

        return arch_type, details

    def _probe_graphql(self) -> dict | None:
        """Check common GraphQL endpoints and attempt introspection.

        GraphQL introspection POST is a read-only exception to the no-mutation rule.
        The introspection query only reads schema metadata, never mutates data.

        Returns:
            Dict with GraphQL endpoint info if found, None otherwise.
        """
        if not self.http:
            return None

        for path in self.GRAPHQL_PATHS:
            url = f"{self.base_url}{path}"

            # Check budget before each request
            if not self.budget.can_request():
                logger.warning("Discovery request budget exhausted during GraphQL probing")
                break

            # Step 1: POST introspection query (read-only exception to no-mutation rule)
            try:
                evidence = self.http.request(
                    method="POST",
                    url=url,
                    headers={"Content-Type": "application/json"},
                    body={"query": GRAPHQL_INTROSPECTION_QUERY},
                )
                self.budget.record()
                self._evidence_list.append(evidence)

                if evidence.response_status == 200:
                    try:
                        body = json.loads(evidence.response_body)
                        if "data" in body and "__schema" in body.get("data", {}):
                            # Introspection successful
                            schema = body["data"]["__schema"]
                            logger.info("GraphQL introspection successful at %s", url)
                            return {
                                "endpoint": url,
                                "introspection_available": True,
                                "query_type": schema.get("queryType", {}).get("name"),
                                "mutation_type": schema.get("mutationType", {}).get("name")
                                if schema.get("mutationType")
                                else None,
                                "subscription_type": schema.get("subscriptionType", {}).get("name")
                                if schema.get("subscriptionType")
                                else None,
                                "type_count": len(schema.get("types", [])),
                                "directive_count": len(schema.get("directives", [])),
                            }
                        elif "errors" in body:
                            # GraphQL endpoint exists but introspection disabled
                            logger.info("GraphQL detected at %s (introspection disabled)", url)
                            return {
                                "endpoint": url,
                                "introspection_available": False,
                                "reason": "Introspection query returned errors",
                            }
                    except (json.JSONDecodeError, TypeError):
                        # Not JSON or invalid structure, continue to next path
                        pass

            except Exception as e:
                logger.debug("GraphQL probe POST failed for %s: %s", url, e)

            # Step 2 fallback: GET with query param (some servers support this)
            # Check budget before request
            if not self.budget.can_request():
                logger.warning("Discovery request budget exhausted during GraphQL GET fallback")
                break

            try:
                evidence_get = self.http.request(
                    method="GET",
                    url=f"{url}?query={{__typename}}",
                    headers={},
                )
                self.budget.record()
                self._evidence_list.append(evidence_get)

                if evidence_get.response_status == 200:
                    try:
                        body = json.loads(evidence_get.response_body)
                        if "data" in body:
                            logger.info("GraphQL detected at %s via GET (introspection not attempted)", url)
                            return {
                                "endpoint": url,
                                "introspection_available": False,
                                "reason": "GraphQL detected via __typename, introspection not attempted via GET",
                            }
                    except (json.JSONDecodeError, TypeError):
                        pass

            except Exception as e:
                logger.debug("GraphQL probe GET failed for %s: %s", url, e)

        return None

    def _collect_server_info(self, evidence_list: list[Evidence]) -> dict:
        """Extract server fingerprint and security headers from responses.

        Args:
            evidence_list: List of Evidence objects from probing

        Returns:
            Dict with server_fingerprint, content_types_observed, security_headers
        """
        server_header = ""
        content_types: set[str] = set()
        security_headers: dict[str, str] = {}

        for evidence in evidence_list:
            for header_name, header_val in evidence.response_headers.items():
                lower_name = header_name.lower()

                # Server fingerprint (first non-empty value)
                if lower_name == "server" and not server_header:
                    server_header = header_val

                # Content-Type (normalize: strip charset)
                elif lower_name == "content-type":
                    ct = header_val.split(";")[0].strip().lower()
                    content_types.add(ct)

                # Security headers
                elif lower_name in self.SECURITY_HEADER_NAMES:
                    if lower_name not in security_headers:
                        security_headers[lower_name] = header_val

        return {
            "server_fingerprint": server_header or "unknown",
            "content_types_observed": sorted(content_types),
            "security_headers": security_headers,
        }


# =============================================================================
# Profile System - Version, Constants, Dataclass
# =============================================================================

PROFILE_VERSION = 1  # Increment on breaking schema changes


@dataclass
class ApiProfile:
    """Complete profile of a discovered API.

    Captures all discovery results: auth schemes, architecture type, endpoint
    classifications, response patterns, prerequisite detection results, and
    server metadata. Serializes to JSON for caching.
    """

    profile_version: int = PROFILE_VERSION
    created_at: str = ""  # ISO 8601 timestamp
    content_hash: str = ""  # SHA-256 of spec + base_url for staleness detection
    base_url: str = ""
    input_format: str = ""  # e.g. "openapi_3.0", "swagger_2.0", "postman_v2.1"
    endpoint_count: int = 0
    auth_schemes: list[dict] = field(default_factory=list)  # Serialized DetectedAuthScheme list
    architecture_type: str = ""  # ArchitectureType.value
    architecture_details: dict = field(default_factory=dict)
    classifications: dict = field(default_factory=dict)  # e.g. {"public": 3, "protected": 7}
    response_pattern_count: int = 0
    server_fingerprint: str = ""
    content_types_observed: list[str] = field(default_factory=list)
    security_headers: dict = field(default_factory=dict)
    prerequisites: dict = field(default_factory=dict)  # e.g. {"rate_limiting": {"status": "ABSENT"}}
    gaps: list[str] = field(default_factory=list)  # Discovery gaps logged as strings


# =============================================================================
# Profile Persistence Functions
# =============================================================================


def compute_content_hash(spec_data: dict | None, base_url: str) -> str:
    """Compute a deterministic SHA-256 hash of spec content + base_url.

    Used for staleness detection -- if hash differs, profile is stale.
    """
    import hashlib

    content = json.dumps(spec_data, sort_keys=True) if spec_data else ""
    content += f"|{base_url}"
    return hashlib.sha256(content.encode("utf-8")).hexdigest()


def save_profile(profile: ApiProfile, profiles_dir: str, target_name: str) -> "Path":
    """Save profile to JSON file in profiles directory.

    Args:
        profile: ApiProfile to save
        profiles_dir: Directory path for profiles
        target_name: Name to use for file (sanitized)

    Returns:
        Path to saved file
    """
    from dataclasses import asdict
    from pathlib import Path

    # Create directory if needed
    path = Path(profiles_dir)
    path.mkdir(parents=True, exist_ok=True)

    # Sanitize target_name: replace non-alphanumeric (except hyphen/dot) with hyphen
    safe_name = re.sub(r"[^a-zA-Z0-9.-]", "-", target_name)
    safe_name = re.sub(r"-+", "-", safe_name).strip("-")  # Collapse multiple hyphens
    if not safe_name:
        safe_name = "unknown-api"

    file_path = path / f"{safe_name}.profile.json"

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(asdict(profile), f, indent=2, default=str)

    logger.info("Saved API profile to %s", file_path)
    return file_path


def load_profile(file_path: "Path") -> ApiProfile | None:
    """Load profile from JSON file.

    Returns None if file doesn't exist or has incompatible version.
    """
    from pathlib import Path

    file_path = Path(file_path)
    if not file_path.exists():
        return None

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # Version check -- reject incompatible profiles
        if data.get("profile_version") != PROFILE_VERSION:
            logger.warning(
                "Profile version mismatch: file=%s, expected=%s. Re-discovery required.",
                data.get("profile_version"),
                PROFILE_VERSION,
            )
            return None

        return ApiProfile(**data)

    except (json.JSONDecodeError, TypeError, KeyError) as e:
        logger.warning("Failed to load profile from %s: %s", file_path, e)
        return None


def is_profile_stale(profile: ApiProfile, current_hash: str) -> bool:
    """Check if profile is stale based on content hash."""
    return profile.content_hash != current_hash


def derive_target_name(input_file: str, base_url: str) -> str:
    """Derive a target name from input file or base URL.

    Used for naming profile files.
    """
    from pathlib import Path
    from urllib.parse import urlparse

    if input_file:
        # Derive from filename
        name = Path(input_file).stem
    elif base_url:
        # Derive from hostname + port
        parsed = urlparse(base_url)
        host = parsed.hostname or "unknown"
        port = parsed.port
        name = f"{host}-{port}" if port and port not in (80, 443) else host
    else:
        name = "unknown-api"

    # Sanitize: replace non-alphanumeric (except hyphen/dot) with hyphen
    name = re.sub(r"[^a-zA-Z0-9.-]", "-", name)
    name = re.sub(r"-+", "-", name).strip("-")

    return name or "unknown-api"


# =============================================================================
# ApiProfiler - Orchestrator
# =============================================================================


class ApiProfiler:
    """Orchestrates API discovery and produces a complete ApiProfile.

    Combines AuthDetector and ArchitectureDetector results with endpoint
    classifications, response patterns, and prerequisite detection into
    a unified profile. Handles caching via JSON persistence.
    """

    def __init__(
        self,
        openapi_spec: dict | None,
        http_client: Any,
        endpoints: list,
        config: dict,
        response_learner: Any = None,
        prerequisite_results: dict | None = None,
    ):
        """Initialize ApiProfiler.

        Args:
            openapi_spec: Parsed OpenAPI/Swagger spec dict, or None
            http_client: PentestHttpClient instance
            endpoints: List of Endpoint objects
            config: Runner config dict (contains base_url, input_file, etc.)
            response_learner: ResponsePatternLearner instance (optional)
            prerequisite_results: PrerequisiteChecker results dict (optional)
        """
        self.spec = openapi_spec
        self.http = http_client
        self.endpoints = endpoints
        self.config = config
        self.response_learner = response_learner
        self.prerequisite_results = prerequisite_results or {}

        # Extract base_url from config or first endpoint
        self.base_url = config.get("base_url", "")
        if not self.base_url and endpoints:
            # Derive from first endpoint URL
            from urllib.parse import urlparse

            parsed = urlparse(endpoints[0].url)
            self.base_url = f"{parsed.scheme}://{parsed.netloc}"

        # Shared request budget for all detectors
        self.budget = RequestBudget(max_requests=30)

        # Create detectors
        self.auth_detector = AuthDetector(
            openapi_spec=self.spec,
            http_client=self.http,
            endpoints=self.endpoints,
            base_url=self.base_url,
            budget=self.budget,
        )
        self.architecture_detector = ArchitectureDetector(
            openapi_spec=self.spec,
            http_client=self.http,
            base_url=self.base_url,
            budget=self.budget,
        )

    def discover(self) -> ApiProfile:
        """Run full API discovery and produce ApiProfile.

        Calls AuthDetector and ArchitectureDetector, aggregates all results
        into a unified profile.
        """
        from datetime import datetime, timezone

        gaps: list[str] = []

        # Run auth detection
        auth_schemes = self.auth_detector.detect()
        if not auth_schemes:
            gaps.append("No auth schemes detected from spec or probing")

        # Run architecture detection
        arch_type, arch_details = self.architecture_detector.detect()

        # Collect server info from architecture detector's evidence
        server_info = {}
        if self.architecture_detector._evidence_list:
            server_info = self.architecture_detector._collect_server_info(
                self.architecture_detector._evidence_list
            )

        # Check budget exhaustion
        if not self.budget.can_request():
            gaps.append(f"Discovery request budget exhausted ({self.budget.max_requests} requests used)")

        # Aggregate endpoint classifications
        classifications: dict[str, int] = {}
        for ep in self.endpoints:
            if hasattr(ep, "classification") and ep.classification:
                cls_name = ep.classification.value if hasattr(ep.classification, "value") else str(ep.classification)
                classifications[cls_name] = classifications.get(cls_name, 0) + 1

        # Count response patterns
        response_pattern_count = 0
        if self.response_learner and hasattr(self.response_learner, "patterns"):
            response_pattern_count = len(self.response_learner.patterns)
        elif not self.response_learner:
            gaps.append("Response learner not provided -- no pattern data")

        # Serialize prerequisite results
        prereq_data: dict[str, Any] = {}
        if self.prerequisite_results:
            for key, result in self.prerequisite_results.items():
                if hasattr(result, "status"):
                    prereq_data[key] = {
                        "status": result.status.value if hasattr(result.status, "value") else str(result.status),
                        "reason": getattr(result, "reason", ""),
                    }
                else:
                    prereq_data[key] = result

        # Serialize auth schemes to dicts
        auth_scheme_dicts = []
        for scheme in auth_schemes:
            auth_scheme_dicts.append({
                "scheme_type": scheme.scheme_type.value if hasattr(scheme.scheme_type, "value") else str(scheme.scheme_type),
                "name": scheme.name,
                "source": scheme.source,
                "details": scheme.details,
                "endpoints": scheme.endpoints,
            })

        # Determine input format
        input_format = ""
        if self.spec:
            if self.spec.get("openapi", "").startswith("3.1"):
                input_format = "openapi_3.1"
            elif self.spec.get("openapi", "").startswith("3."):
                input_format = "openapi_3.0"
            elif self.spec.get("swagger") == "2.0":
                input_format = "swagger_2.0"

        # Build profile
        profile = ApiProfile(
            profile_version=PROFILE_VERSION,
            created_at=datetime.now(timezone.utc).isoformat(),
            content_hash=compute_content_hash(self.spec, self.base_url),
            base_url=self.base_url,
            input_format=input_format,
            endpoint_count=len(self.endpoints),
            auth_schemes=auth_scheme_dicts,
            architecture_type=arch_type.value if hasattr(arch_type, "value") else str(arch_type),
            architecture_details=arch_details,
            classifications=classifications,
            response_pattern_count=response_pattern_count,
            server_fingerprint=server_info.get("server_fingerprint", ""),
            content_types_observed=server_info.get("content_types_observed", []),
            security_headers=server_info.get("security_headers", {}),
            prerequisites=prereq_data,
            gaps=gaps,
        )

        # Log discovery summary
        logger.info(
            "API Discovery complete: auth=%d schemes, arch=%s, endpoints=%d, patterns=%d, prereqs=%d",
            len(auth_schemes),
            arch_type.value,
            len(self.endpoints),
            response_pattern_count,
            len(prereq_data),
        )

        return profile

    def load_cached_profile(self) -> ApiProfile | None:
        """Load profile from cache if available.

        Returns None if no cached profile exists.
        """
        from pathlib import Path

        target_name = derive_target_name(
            self.config.get("input_file", ""),
            self.base_url,
        )
        profiles_dir = self.config.get("profiles_dir", "profiles")
        file_path = Path(profiles_dir) / f"{target_name}.profile.json"

        return load_profile(file_path)

    def is_stale(self, profile: ApiProfile) -> bool:
        """Check if a cached profile is stale."""
        current_hash = compute_content_hash(self.spec, self.base_url)
        return is_profile_stale(profile, current_hash)

    def save(self, profile: ApiProfile) -> "Path":
        """Save profile to cache."""
        target_name = derive_target_name(
            self.config.get("input_file", ""),
            self.base_url,
        )
        profiles_dir = self.config.get("profiles_dir", "profiles")

        return save_profile(profile, profiles_dir, target_name)
