"""
Race condition detector for API security testing.

This module provides RaceConditionTester which sends concurrent requests
to detect Time-Of-Check-Time-Of-Use (TOCTOU) vulnerabilities, double-spend
issues, and race conditions in authentication/authorization.

Common vulnerability patterns:
- Double withdrawal/transfer in financial APIs
- Coupon/discount code reuse
- Parallel account creation bypassing uniqueness checks
- Session invalidation race conditions
- Inventory overselling

Usage:
    from api_pentest.core.race_condition import RaceConditionTester

    tester = RaceConditionTester(http_client)

    # Test for double-spend
    result = tester.test_double_action(
        url="https://api.example.com/transfer",
        method="POST",
        body={"amount": 100, "to": "attacker"},
        success_indicator=lambda r: r.status_code == 200,
    )

    if result.is_vulnerable:
        print(f"Race condition found! {result.successful_count} requests succeeded")
"""

import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from typing import Any, Callable, TYPE_CHECKING

if TYPE_CHECKING:
    from api_pentest.core.http_client import PentestHttpClient
    from api_pentest.core.models import Evidence

logger = logging.getLogger(__name__)


@dataclass
class RaceResult:
    """Result of a race condition test."""
    is_vulnerable: bool
    total_requests: int
    successful_count: int
    failed_count: int
    error_count: int
    responses: list["Evidence"]
    timing_ms: float
    description: str = ""
    vulnerability_type: str = ""  # e.g., "double-spend", "auth-bypass"


@dataclass
class RaceConfig:
    """Configuration for race condition testing."""
    concurrent_requests: int = 10  # Number of parallel requests
    rounds: int = 3  # Number of test rounds
    delay_between_rounds_ms: int = 100  # Delay between rounds
    timeout_seconds: float = 30.0  # Per-request timeout
    barrier_sync: bool = True  # Use barrier for tight synchronization


class RaceConditionTester:
    """Tests for race condition vulnerabilities in APIs.

    Sends multiple concurrent requests to detect scenarios where
    the application fails to properly handle simultaneous operations.
    """

    def __init__(self, http_client: "PentestHttpClient"):
        """Initialize RaceConditionTester.

        Args:
            http_client: HTTP client for making requests
        """
        self.http = http_client
        self._barrier: threading.Barrier | None = None

    def test_double_action(
        self,
        url: str,
        method: str = "POST",
        headers: dict[str, str] | None = None,
        body: Any = None,
        success_indicator: Callable[["Evidence"], bool] | None = None,
        config: RaceConfig | None = None,
    ) -> RaceResult:
        """Test for double-action vulnerabilities (double-spend, double-use).

        Sends multiple identical requests simultaneously to see if an action
        that should only succeed once can succeed multiple times.

        Args:
            url: Target URL
            method: HTTP method
            headers: Request headers
            body: Request body
            success_indicator: Function to determine if request was successful
                             (default: status 200-299)
            config: Race test configuration

        Returns:
            RaceResult with vulnerability assessment
        """
        config = config or RaceConfig()

        if success_indicator is None:
            success_indicator = lambda e: 200 <= e.response_status < 300

        all_responses: list["Evidence"] = []
        total_successful = 0
        total_failed = 0
        total_errors = 0

        start_time = time.time()

        for round_num in range(config.rounds):
            logger.debug(f"Race test round {round_num + 1}/{config.rounds}")

            responses, successful, failed, errors = self._send_concurrent(
                url=url,
                method=method,
                headers=headers,
                body=body,
                success_indicator=success_indicator,
                config=config,
            )

            all_responses.extend(responses)
            total_successful += successful
            total_failed += failed
            total_errors += errors

            if round_num < config.rounds - 1:
                time.sleep(config.delay_between_rounds_ms / 1000)

        elapsed_ms = (time.time() - start_time) * 1000

        # Determine vulnerability
        # If more than 1 request succeeded per round, it's likely vulnerable
        expected_successes = config.rounds  # 1 per round max
        is_vulnerable = total_successful > expected_successes

        return RaceResult(
            is_vulnerable=is_vulnerable,
            total_requests=len(all_responses),
            successful_count=total_successful,
            failed_count=total_failed,
            error_count=total_errors,
            responses=all_responses,
            timing_ms=elapsed_ms,
            description=self._describe_result(total_successful, expected_successes, config),
            vulnerability_type="double-action" if is_vulnerable else "",
        )

    def test_limit_bypass(
        self,
        url: str,
        method: str = "POST",
        headers: dict[str, str] | None = None,
        body: Any = None,
        limit: int = 1,
        success_indicator: Callable[["Evidence"], bool] | None = None,
        config: RaceConfig | None = None,
    ) -> RaceResult:
        """Test if a rate/quantity limit can be bypassed via race condition.

        Useful for testing:
        - Coupon/promo code use limits
        - Vote limits
        - Daily action limits
        - Inventory limits

        Args:
            url: Target URL
            method: HTTP method
            headers: Request headers
            body: Request body
            limit: Expected maximum successful requests
            success_indicator: Function to determine if request was successful
            config: Race test configuration

        Returns:
            RaceResult with vulnerability assessment
        """
        config = config or RaceConfig()

        if success_indicator is None:
            success_indicator = lambda e: 200 <= e.response_status < 300

        start_time = time.time()

        responses, successful, failed, errors = self._send_concurrent(
            url=url,
            method=method,
            headers=headers,
            body=body,
            success_indicator=success_indicator,
            config=config,
        )

        elapsed_ms = (time.time() - start_time) * 1000

        is_vulnerable = successful > limit

        return RaceResult(
            is_vulnerable=is_vulnerable,
            total_requests=len(responses),
            successful_count=successful,
            failed_count=failed,
            error_count=errors,
            responses=responses,
            timing_ms=elapsed_ms,
            description=f"Limit bypass: {successful}/{limit} succeeded (expected max {limit})",
            vulnerability_type="limit-bypass" if is_vulnerable else "",
        )

    def test_auth_race(
        self,
        auth_url: str,
        protected_url: str,
        auth_method: str = "POST",
        auth_headers: dict[str, str] | None = None,
        auth_body: Any = None,
        protected_method: str = "GET",
        protected_headers: dict[str, str] | None = None,
        protected_body: Any = None,
        config: RaceConfig | None = None,
    ) -> RaceResult:
        """Test for authentication race conditions.

        Sends requests to a protected endpoint while simultaneously
        sending auth requests, to see if there's a window where
        the protected endpoint can be accessed.

        Args:
            auth_url: Authentication endpoint
            protected_url: Protected resource endpoint
            auth_method: HTTP method for auth
            auth_headers: Headers for auth request
            auth_body: Body for auth request
            protected_method: HTTP method for protected resource
            protected_headers: Headers for protected resource
            protected_body: Body for protected resource
            config: Race test configuration

        Returns:
            RaceResult with vulnerability assessment
        """
        config = config or RaceConfig(concurrent_requests=20)

        all_responses: list["Evidence"] = []
        protected_successes = 0
        protected_failures = 0
        auth_responses = 0

        start_time = time.time()

        # Create a barrier for tight synchronization
        if config.barrier_sync:
            self._barrier = threading.Barrier(config.concurrent_requests)

        def make_auth_request():
            nonlocal auth_responses
            if self._barrier and config.barrier_sync:
                self._barrier.wait()
            try:
                evidence = self.http.request(
                    method=auth_method,
                    url=auth_url,
                    headers=auth_headers or {},
                    body=auth_body,
                )
                auth_responses += 1
                return ("auth", evidence)
            except Exception as e:
                logger.debug(f"Auth request error: {e}")
                return ("auth_error", None)

        def make_protected_request():
            nonlocal protected_successes, protected_failures
            if self._barrier and config.barrier_sync:
                self._barrier.wait()
            try:
                evidence = self.http.request(
                    method=protected_method,
                    url=protected_url,
                    headers=protected_headers or {},
                    body=protected_body,
                )
                if 200 <= evidence.response_status < 300:
                    protected_successes += 1
                else:
                    protected_failures += 1
                return ("protected", evidence)
            except Exception as e:
                logger.debug(f"Protected request error: {e}")
                return ("protected_error", None)

        # Mix auth and protected requests
        with ThreadPoolExecutor(max_workers=config.concurrent_requests) as executor:
            futures = []

            # Half auth, half protected
            for i in range(config.concurrent_requests):
                if i % 2 == 0:
                    futures.append(executor.submit(make_auth_request))
                else:
                    futures.append(executor.submit(make_protected_request))

            for future in as_completed(futures, timeout=config.timeout_seconds):
                try:
                    req_type, evidence = future.result()
                    if evidence:
                        all_responses.append(evidence)
                except Exception as e:
                    logger.debug(f"Future error: {e}")

        elapsed_ms = (time.time() - start_time) * 1000

        # Vulnerable if any protected request succeeded without proper auth
        is_vulnerable = protected_successes > 0

        return RaceResult(
            is_vulnerable=is_vulnerable,
            total_requests=len(all_responses),
            successful_count=protected_successes,
            failed_count=protected_failures,
            error_count=config.concurrent_requests - len(all_responses),
            responses=all_responses,
            timing_ms=elapsed_ms,
            description=f"Auth race: {protected_successes} protected requests succeeded during auth",
            vulnerability_type="auth-race" if is_vulnerable else "",
        )

    def test_session_invalidation(
        self,
        logout_url: str,
        protected_url: str,
        session_token: str,
        logout_method: str = "POST",
        protected_method: str = "GET",
        token_header: str = "Authorization",
        token_prefix: str = "Bearer ",
        config: RaceConfig | None = None,
    ) -> RaceResult:
        """Test if session can be used during logout process.

        Sends protected requests while simultaneously logging out,
        to detect session invalidation race conditions.

        Args:
            logout_url: Logout endpoint
            protected_url: Protected resource
            session_token: Current session token
            logout_method: HTTP method for logout
            protected_method: HTTP method for protected resource
            token_header: Header name for token
            token_prefix: Token prefix (e.g., "Bearer ")
            config: Race test configuration

        Returns:
            RaceResult with vulnerability assessment
        """
        config = config or RaceConfig(concurrent_requests=10)

        auth_header = {token_header: f"{token_prefix}{session_token}"}

        all_responses: list["Evidence"] = []
        protected_after_logout = 0
        logout_completed = threading.Event()

        start_time = time.time()

        if config.barrier_sync:
            self._barrier = threading.Barrier(config.concurrent_requests)

        def make_logout_request():
            nonlocal logout_completed
            if self._barrier and config.barrier_sync:
                self._barrier.wait()
            try:
                evidence = self.http.request(
                    method=logout_method,
                    url=logout_url,
                    headers=auth_header,
                )
                logout_completed.set()
                return ("logout", evidence)
            except Exception as e:
                logger.debug(f"Logout error: {e}")
                return ("logout_error", None)

        def make_protected_request():
            nonlocal protected_after_logout
            if self._barrier and config.barrier_sync:
                self._barrier.wait()
            # Small delay to ensure we're testing during/after logout
            time.sleep(0.001)
            try:
                evidence = self.http.request(
                    method=protected_method,
                    url=protected_url,
                    headers=auth_header,
                )
                if 200 <= evidence.response_status < 300:
                    protected_after_logout += 1
                return ("protected", evidence)
            except Exception as e:
                logger.debug(f"Protected error: {e}")
                return ("protected_error", None)

        with ThreadPoolExecutor(max_workers=config.concurrent_requests) as executor:
            futures = []

            # 1 logout, rest protected
            futures.append(executor.submit(make_logout_request))
            for _ in range(config.concurrent_requests - 1):
                futures.append(executor.submit(make_protected_request))

            for future in as_completed(futures, timeout=config.timeout_seconds):
                try:
                    req_type, evidence = future.result()
                    if evidence:
                        all_responses.append(evidence)
                except Exception as e:
                    logger.debug(f"Future error: {e}")

        elapsed_ms = (time.time() - start_time) * 1000

        # Vulnerable if protected requests succeeded during/after logout
        is_vulnerable = protected_after_logout > 0

        return RaceResult(
            is_vulnerable=is_vulnerable,
            total_requests=len(all_responses),
            successful_count=protected_after_logout,
            failed_count=len(all_responses) - protected_after_logout - 1,  # -1 for logout
            error_count=config.concurrent_requests - len(all_responses),
            responses=all_responses,
            timing_ms=elapsed_ms,
            description=f"Session race: {protected_after_logout} requests succeeded during logout",
            vulnerability_type="session-invalidation" if is_vulnerable else "",
        )

    def _send_concurrent(
        self,
        url: str,
        method: str,
        headers: dict[str, str] | None,
        body: Any,
        success_indicator: Callable[["Evidence"], bool],
        config: RaceConfig,
    ) -> tuple[list["Evidence"], int, int, int]:
        """Send concurrent requests and count results.

        Returns:
            Tuple of (responses, successful_count, failed_count, error_count)
        """
        responses: list["Evidence"] = []
        successful = 0
        failed = 0
        errors = 0

        # Create barrier for tight synchronization
        if config.barrier_sync:
            self._barrier = threading.Barrier(config.concurrent_requests)

        def make_request() -> tuple[str, "Evidence | None"]:
            # Wait at barrier for synchronized start
            if self._barrier and config.barrier_sync:
                try:
                    self._barrier.wait(timeout=5)
                except threading.BrokenBarrierError:
                    return ("barrier_error", None)

            try:
                evidence = self.http.request(
                    method=method,
                    url=url,
                    headers=headers or {},
                    body=body,
                )
                return ("success" if success_indicator(evidence) else "failed", evidence)
            except Exception as e:
                logger.debug(f"Request error: {e}")
                return ("error", None)

        with ThreadPoolExecutor(max_workers=config.concurrent_requests) as executor:
            futures = [
                executor.submit(make_request)
                for _ in range(config.concurrent_requests)
            ]

            for future in as_completed(futures, timeout=config.timeout_seconds):
                try:
                    status, evidence = future.result()
                    if evidence:
                        responses.append(evidence)
                    if status == "success":
                        successful += 1
                    elif status == "failed":
                        failed += 1
                    else:
                        errors += 1
                except Exception as e:
                    logger.debug(f"Future error: {e}")
                    errors += 1

        return responses, successful, failed, errors

    def _describe_result(self, successful: int, expected: int, config: RaceConfig) -> str:
        """Generate human-readable result description."""
        if successful > expected:
            return (
                f"VULNERABLE: {successful} requests succeeded "
                f"(expected max {expected} across {config.rounds} rounds). "
                f"Race condition allows duplicate actions."
            )
        elif successful == expected:
            return (
                f"SECURE: Exactly {successful} requests succeeded as expected. "
                f"Proper serialization/locking in place."
            )
        else:
            return (
                f"PARTIAL: Only {successful}/{expected} requests succeeded. "
                f"May indicate rate limiting or other controls."
            )


# Convenience functions
def test_race_condition(
    http_client: "PentestHttpClient",
    url: str,
    method: str = "POST",
    headers: dict = None,
    body: Any = None,
    concurrent: int = 10,
) -> RaceResult:
    """Quick race condition test.

    Args:
        http_client: HTTP client
        url: Target URL
        method: HTTP method
        headers: Request headers
        body: Request body
        concurrent: Number of concurrent requests

    Returns:
        RaceResult
    """
    tester = RaceConditionTester(http_client)
    config = RaceConfig(concurrent_requests=concurrent, rounds=1)
    return tester.test_double_action(url, method, headers, body, config=config)
